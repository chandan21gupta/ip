{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.svm import FastSurvivalSVM\n",
    "import lifelines\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "# from sklearn_pandas import CategoricalImputer\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import kendall_w as kw\n",
    "\n",
    "import warnings\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from pymc3.distributions import Interpolated\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from statsmodels import datasets\n",
    "from theano import shared\n",
    "from theano import tensor as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(31415)\n",
    "random_state = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('../../data/brca_metabric_clinical_data.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data.drop(['Study ID', 'Patient ID', 'Sample ID', 'Type of Breast Surgery', 'Cancer Type Detailed', 'Cohort'\n",
    "                  , 'HER2 status measured by SNP6', 'Hormone Therapy', 'Integrative Cluster', 'Oncotree Code', 'Pam50 + Claudin-low subtype'\n",
    "                  , 'ER status measured by IHC', 'Number of Samples Per Patient', 'Patient\\'s Vital Status', 'Radio Therapy'\n",
    "                   , 'Sex', 'Cancer Type', 'Tumor Stage', 'Sample Type', '3-Gene classifier subtype', 'Tumor Other Histologic Subtype'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_columns = ['Cellularity', 'Chemotherapy', 'ER Status', 'HER2 Status', \n",
    "                 'Inferred Menopausal State', 'Primary Tumor Laterality', 'PR Status', 'Neoplasm Histologic Grade']\n",
    "numerical_columns = ['Age at Diagnosis', 'Lymph nodes examined positive', 'Mutation Count',\n",
    "                    'Nottingham prognostic index', 'Relapse Free Status (Months)', 'Tumor Size']\n",
    "labels = ['Overall Survival Status', 'Overall Survival (Months)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data_[data_['Overall Survival Status'].notna()]\n",
    "data_ = data_[data_['Overall Survival (Months)'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'0:LIVING': False, '1:DECEASED': True}\n",
    "data_['Overall Survival Status'] = data_['Overall Survival Status'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data_[numerical_columns+leave_columns]\n",
    "Y_data = data_[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.20, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer_imputer = [([col], [SimpleImputer(missing_values = np.nan, strategy = 'mean')]) for col in numerical_columns]\n",
    "col_imputer = [([col], [SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')]) for col in leave_columns]\n",
    "imputer_mapper = DataFrameMapper(numer_imputer + col_imputer, df_out = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imputer_mapper.fit_transform(X_train)\n",
    "X_test = imputer_mapper.transform(X_test)\n",
    "# x_train_double_temp = inference_mapper.fit_transform(X_train)\n",
    "# categorical_features = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "categorical_names = {}\n",
    "i = 6\n",
    "for feature in leave_columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X_train[feature])\n",
    "    X_train[feature] = le.transform(X_train[feature])\n",
    "    X_test[feature] = le.transform(X_test[feature])\n",
    "    categorical_names[i] = le.classes_\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer_preprocess = [([col], [MinMaxScaler()]) for col in numerical_columns]\n",
    "leave_preprocess = [([col], [OneHotEncoder()]) for col in leave_columns]\n",
    "encoder_mapper = DataFrameMapper(numer_preprocess+leave_preprocess, df_out = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mapper_temp = DataFrameMapper(numer_preprocess+leave_preprocess, df_out = True)\n",
    "x_temp = x_mapper_temp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = encoder_mapper.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_final = y_train.to_records(index = False, column_dtypes = {'Overall Survival' : 'u1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log_t = y_train_final.copy()\n",
    "y_train_log_t['Overall Survival (Months)'] = np.log1p(y_train_final['Overall Survival (Months)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915\n"
     ]
    }
   ],
   "source": [
    "ref_estimator = FastSurvivalSVM(rank_ratio=0.0, max_iter=1000, tol=1e-5, random_state=0)\n",
    "ref_estimator.fit(x_train, y_train_log_t)\n",
    "\n",
    "cindex = concordance_index_censored(\n",
    "    y_train_final['Overall Survival Status'],\n",
    "    y_train_final['Overall Survival (Months)'],\n",
    "    -ref_estimator.predict(x_train),  # flip sign to obtain risk scores\n",
    ")\n",
    "print(round(cindex[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_final = y_test.to_records(index = False, column_dtypes = {'Overall Survival' : 'u1'})\n",
    "y_test_final\n",
    "x_test = encoder_mapper.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896\n"
     ]
    }
   ],
   "source": [
    "# pred_y = np.expm1(ref_estimator.predict(x_test))\n",
    "cindex = concordance_index_censored(\n",
    "    y_test_final['Overall Survival Status'],\n",
    "    y_test_final['Overall Survival (Months)'],\n",
    "    -ref_estimator.predict(x_test),  # flip sign to obtain risk scores\n",
    ")\n",
    "print(round(cindex[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "def predict_fn(x):\n",
    "    df = pd.DataFrame(x, columns = numerical_columns+leave_columns)\n",
    "    return ref_estimator.predict(encoder_mapper.transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy() ,feature_names = numerical_columns+leave_columns,\n",
    "                                                   categorical_features=categorical_features, \n",
    "                                                   categorical_names=categorical_names, kernel_width=3, mode='regression', feature_selection = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    y = np.exp(x)\n",
    "    f_x = y / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "def censored_distances(survival_status, event, distances):\n",
    "    cens_dist = np.abs(survival_status - event)\n",
    "    return np.sqrt(np.square(distances)+cens_dist)\n",
    "\n",
    "def gumbel_sf(y, μ, σ):\n",
    "    return 1.0 - tt.exp(-tt.exp(-(y - μ) / σ))\n",
    "\n",
    "def train_model(sample_X, y_std, cens, distances):\n",
    "    cens_ = shared(cens)\n",
    "    with pm.Model() as model:\n",
    "        distances_ = pm.Data(\"distance\", distances)\n",
    "        sample_X_ = pm.Data(\"data\", sample_X)\n",
    "        sigma_squared = pm.HalfNormal(\"sigma_squared\", 5)\n",
    "        beta = pm.Normal(\"beta\", 0.0, sigma_squared, shape = sample_X.shape[1])\n",
    "        eta = beta.dot(sample_X_.T)\n",
    "        y_obs = pm.Gumbel(\"y_obs\", eta[~cens_], sigma_squared/distances_[~cens_], observed=y_std[~cens])\n",
    "        y_cens = pm.Potential(\"y_cens\", gumbel_sf(y_std[cens], eta[cens_], sigma_squared/distances_[cens_]))\n",
    "    SEED = 845199  # from random.org, for reproducibility\n",
    "    SAMPLE_KWARGS = {\"chains\": 3, \"tune\": 100, \"random_seed\": [SEED, SEED + 1, SEED + 2], \"target_accept\" : 0.9}\n",
    "    with model:\n",
    "        weibull_trace = pm.sample(**SAMPLE_KWARGS)\n",
    "    return model, weibull_trace, cens_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def censored_focussed_sampling(explainer, point, i, y_train, y_test_final, S, N, A, batch_size, predict_fn):\n",
    "#     x_test = X_test.to_numpy()\n",
    "    samples, y_std, distances = explainer.generate_samples(point, predict_fn, S)\n",
    "    unique, counts = np.unique(y_train['Overall Survival Status'], return_counts=True)\n",
    "    p1 = counts[0]/sum(counts)\n",
    "    p2 = counts[1]/sum(counts)\n",
    "    event = np.random.choice([0, 1], size = S-1, p = [p1, p2])\n",
    "    X_sample = np.empty((samples.shape[0], samples.shape[1]+1))\n",
    "    X_sample[:, 0] = 1\n",
    "    for i in range(samples.shape[1]):\n",
    "        X_sample[:, i+1] = samples[:, i]\n",
    "    X_sample = X_sample[1:, :]\n",
    "    y_std = y_std[1:]\n",
    "    distances = distances[1:]\n",
    "    distances = censored_distances(y_test_final['Overall Survival Status'][i], event, distances)\n",
    "    model, weibull_trace, cens_ = train_model(X_sample, y_std, event==0, distances)\n",
    "    return model, weibull_trace, cens_\n",
    "#     for _ in range(0, N-S, batch_size):\n",
    "#         samples, y_std_sampled, distances_sampled = explainer.generate_samples(x_test[i], predict_fn, A)\n",
    "#         X_sampled = np.empty((samples.shape[0], samples.shape[1]+1))\n",
    "#         X_sampled[:, 0] = 1\n",
    "#         for i in range(samples.shape[1]):\n",
    "#             X_sampled[:, i+1] = samples[:, i]\n",
    "#         X_sampled = X_sampled[1:, :]\n",
    "#         y_std_sampled = y_std_sampled[1:]\n",
    "#         event_sampled = np.random.choice([0, 1], size = A-1, p = [p1, p2])\n",
    "#         distances_sampled = censored_distances(y_test_final['Overall Survival Status'][i], event_sampled, distances_sampled[1:])\n",
    "#         cens_pp = np.random.choice([False, True], size = A-1, p = [1, 0])\n",
    "#         cens_.set(cens_pp)\n",
    "#         with model:\n",
    "#             pm.set_data({\"data\" : X_sampled, \"distances\" : distances_sampled})\n",
    "#             pp_weibull_trace = pm.sample_posterior_predictive(weibull_trace, samples=1500)\n",
    "#         p_test_pred = np.square(pp_weibull_trace[\"y_obs\"].std(axis=0))\n",
    "#         normalized_sd = softmax(p_test_pred)\n",
    "#         top_k = np.random.choice([i for i in range(p_test_pred.shape[0])], size = batch_size, p = normalized_sd, replace = False)\n",
    "#         selected_X = X_sampled[top_k]\n",
    "#         selected_dist = distances_sampled[top_k]\n",
    "#         selected_event = event_sampled[top_k]\n",
    "# #         cens_.set_value(selected_event == 0)\n",
    "#         selected_y_std = y_std_sampled[top_k]\n",
    "#         X = np.vstack([X, selected_X])\n",
    "#         y_std = np.hstack([y_std, selected_y_std])\n",
    "#         distances = np.hstack([distances, selected_dist])\n",
    "#         event = np.hstack([event, selected_event])\n",
    "#         model, weibull_trace = train_model(X, y_std, event==0, distances)\n",
    "#     df = az.summary(weibull_trace)\n",
    "#     return df['mean'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pymc3/sampling.py:468: FutureWarning: In an upcoming release, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  FutureWarning,\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 4 jobs)\n",
      "NUTS: [beta, sigma_squared]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3300' class='' max='3300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3300/3300 00:13<00:00 Sampling 3 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 100 tune and 1_000 draw iterations (300 + 3_000 draws total) took 23 seconds.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pymc3/sampling.py:468: FutureWarning: In an upcoming release, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  FutureWarning,\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 4 jobs)\n",
      "NUTS: [beta, sigma_squared]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3300' class='' max='3300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3300/3300 00:13<00:00 Sampling 3 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 100 tune and 1_000 draw iterations (300 + 3_000 draws total) took 21 seconds.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "S = 50\n",
    "A = 100\n",
    "N = 50\n",
    "index = 5\n",
    "point = X_test.to_numpy()[index]\n",
    "model, trace, _  = censored_focussed_sampling(explainer, point, index, y_train, y_test_final, S, N, A, batch_size, predict_fn)\n",
    "model_, trace_, _ = censored_focussed_sampling(explainer, point, index, y_train, y_test_final, S, N, A, batch_size, predict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-b4c5a59e8887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomparison\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomparison\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# az.summary(trace)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "comparison = model['data'].get_value() == model_['data'].get_value()\n",
    "print(comparison.all())\n",
    "# az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only convert xarray dataarray, xarray dataset, dict, netcdf filename, numpy array, pystan fit, pymc3 trace, emcee fit, pyro mcmc fit, numpyro mcmc fit, cmdstan fit csv filename, cmdstanpy fit to InferenceData, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-82be0ef724db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/arviz/stats/stats.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(data, var_names, filter_vars, fmt, kind, round_to, include_circ, circ_var_names, stat_funcs, extend, hdi_prob, order, index_origin, skipna, coords, dims, credible_interval)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mhdi_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The value of hdi_prob should be in the interval (0, 1]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m     \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"posterior\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m     \u001b[0mvar_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_var_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvar_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mposterior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/arviz/data/converters.py\u001b[0m in \u001b[0;36mconvert_to_dataset\u001b[0;34m(obj, group, coords, dims)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mxarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \"\"\"\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0minference_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_inference_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/arviz/data/converters.py\u001b[0m in \u001b[0;36mconvert_to_inference_data\u001b[0;34m(obj, group, coords, dims, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m         raise ValueError(\n\u001b[1;32m    132\u001b[0m             \"Can only convert {} to InferenceData, not {}\".format(\n\u001b[0;32m--> 133\u001b[0;31m                 \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallowable_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             )\n\u001b[1;32m    135\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Can only convert xarray dataarray, xarray dataset, dict, netcdf filename, numpy array, pystan fit, pymc3 trace, emcee fit, pyro mcmc fit, numpyro mcmc fit, cmdstan fit csv filename, cmdstanpy fit to InferenceData, not NoneType"
     ]
    }
   ],
   "source": [
    "az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/arviz/data/io_pymc3.py:91: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_mean</th>\n",
       "      <th>ess_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>3.386</td>\n",
       "      <td>0.490</td>\n",
       "      <td>2.464</td>\n",
       "      <td>4.329</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1]</th>\n",
       "      <td>0.737</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.106</td>\n",
       "      <td>1.486</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.008</td>\n",
       "      <td>998.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[2]</th>\n",
       "      <td>0.313</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[3]</th>\n",
       "      <td>0.213</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[4]</th>\n",
       "      <td>0.364</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>1741.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[5]</th>\n",
       "      <td>1.736</td>\n",
       "      <td>0.221</td>\n",
       "      <td>1.339</td>\n",
       "      <td>2.159</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2356.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[6]</th>\n",
       "      <td>-0.264</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>1832.0</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[7]</th>\n",
       "      <td>0.496</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>1371.0</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[8]</th>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[9]</th>\n",
       "      <td>-0.594</td>\n",
       "      <td>0.218</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>1848.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[10]</th>\n",
       "      <td>0.162</td>\n",
       "      <td>0.289</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>1353.0</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>1842.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[11]</th>\n",
       "      <td>0.686</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.187</td>\n",
       "      <td>1.266</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[12]</th>\n",
       "      <td>0.225</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[13]</th>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-0.598</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[14]</th>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_squared</th>\n",
       "      <td>1.114</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.818</td>\n",
       "      <td>1.432</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>1832.0</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_mean  \\\n",
       "beta[0]        3.386  0.490   2.464    4.329      0.014    0.010    1296.0   \n",
       "beta[1]        0.737  0.361   0.106    1.486      0.011    0.008     998.0   \n",
       "beta[2]        0.313  0.205  -0.071    0.710      0.005    0.004    1570.0   \n",
       "beta[3]        0.213  0.274  -0.322    0.717      0.008    0.006    1099.0   \n",
       "beta[4]        0.364  0.240  -0.110    0.795      0.006    0.004    1762.0   \n",
       "beta[5]        1.736  0.221   1.339    2.159      0.005    0.003    2356.0   \n",
       "beta[6]       -0.264  0.202  -0.640    0.106      0.005    0.003    1828.0   \n",
       "beta[7]        0.496  0.253   0.006    0.962      0.007    0.005    1393.0   \n",
       "beta[8]       -0.194  0.221  -0.640    0.204      0.005    0.004    2298.0   \n",
       "beta[9]       -0.594  0.218  -0.989   -0.173      0.005    0.004    1955.0   \n",
       "beta[10]       0.162  0.289  -0.387    0.698      0.007    0.006    1506.0   \n",
       "beta[11]       0.686  0.287   0.187    1.266      0.007    0.006    1489.0   \n",
       "beta[12]       0.225  0.224  -0.212    0.629      0.006    0.004    1603.0   \n",
       "beta[13]      -0.200  0.221  -0.598    0.242      0.006    0.004    1498.0   \n",
       "beta[14]      -0.101  0.219  -0.497    0.308      0.006    0.004    1409.0   \n",
       "sigma_squared  1.114  0.166   0.818    1.432      0.004    0.003    1684.0   \n",
       "\n",
       "               ess_sd  ess_bulk  ess_tail  r_hat  \n",
       "beta[0]        1296.0    1303.0    1405.0   1.00  \n",
       "beta[1]         985.0    1000.0    1435.0   1.01  \n",
       "beta[2]        1570.0    1569.0    2003.0   1.00  \n",
       "beta[3]        1007.0    1102.0    1194.0   1.01  \n",
       "beta[4]        1569.0    1762.0    1741.0   1.00  \n",
       "beta[5]        2296.0    2350.0    1897.0   1.00  \n",
       "beta[6]        1828.0    1832.0    1738.0   1.00  \n",
       "beta[7]        1371.0    1393.0    1569.0   1.00  \n",
       "beta[8]        1685.0    2310.0    1990.0   1.00  \n",
       "beta[9]        1847.0    1967.0    1848.0   1.00  \n",
       "beta[10]       1353.0    1499.0    1842.0   1.00  \n",
       "beta[11]       1332.0    1490.0    1723.0   1.00  \n",
       "beta[12]       1603.0    1604.0    1709.0   1.00  \n",
       "beta[13]       1498.0    1512.0    1773.0   1.00  \n",
       "beta[14]       1409.0    1435.0    1458.0   1.00  \n",
       "sigma_squared  1591.0    1832.0    1575.0   1.00  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "S = 50\n",
    "A = 100\n",
    "N = 50\n",
    "index = 5\n",
    "point = X_test.to_numpy()[index]\n",
    "model_, trace_, _  = censored_focussed_sampling(explainer, point, index, y_train, y_test_final, S, N, A, batch_size, predict_fn)\n",
    "model__, trace__, _ = censored_focussed_sampling(explainer, point, index, y_train, y_test_final, S, N, A, batch_size, predict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = model_[\"data\"].get_value()\n",
    "values_ = model__[\"data\"].get_value()\n",
    "comparison = values == values_\n",
    "print(comparison.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = model[\"distance\"].get_value()\n",
    "values_ = model_[\"distance\"].get_value()\n",
    "comparison = values == values_\n",
    "print(comparison.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = c.get_value(borrow = True)\n",
    "values_ = c.get_value(borrow = True)\n",
    "comparison = values == values_\n",
    "print(comparison.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
