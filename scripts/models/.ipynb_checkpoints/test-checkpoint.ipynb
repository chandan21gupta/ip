{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "\n",
    "# import arviz as az\n",
    "# import numpy as np\n",
    "# import pymc3 as pm\n",
    "# import scipy as sp\n",
    "# import seaborn as sns\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# from matplotlib.ticker import StrMethodFormatter\n",
    "# from statsmodels import datasets\n",
    "# from theano import shared\n",
    "# from theano import tensor as tt\n",
    "\n",
    "# print(f\"Running on PyMC3 v{pm.__version__}\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.svm import FastSurvivalSVM\n",
    "import lifelines\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "# from sklearn_pandas import CategoricalImputer\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import kendall_w as kw\n",
    "\n",
    "import warnings\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from pymc3.distributions import Interpolated\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from statsmodels import datasets\n",
    "from theano import shared\n",
    "from theano import tensor as tt\n",
    "\n",
    "from numpy.random import default_rng\n",
    "random_state = 12345\n",
    "# rng = default_rng(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets.get_rdataset(\"mastectomy\", \"HSAUR\", cache=True).data.assign(\n",
    "    metastized=lambda df: 1.0 * (df.metastized == \"yes\"), event=lambda df: 1.0 * df.event\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patient, _ = df.shape\n",
    "\n",
    "X = np.empty((n_patient, 2))\n",
    "X[:, 0] = 1.0\n",
    "X[:, 1] = df.metastized\n",
    "y = np.log(df.time.values)\n",
    "y_std = (y - y.mean()) / y.std()\n",
    "\n",
    "cens = df.event.values == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel_sf(y, μ, σ):\n",
    "    return 1.0 - tt.exp(-tt.exp(-(y - μ) / σ))\n",
    "\n",
    "def generate_dist():\n",
    "    return rng.choice([0, 1], size = 500)\n",
    "\n",
    "def tutorial_model(X, y_std, cens):\n",
    "#     np.random.seed(1234)\n",
    "    dist = generate_dist()\n",
    "    VAGUE_PRIOR_SD = 5.0\n",
    "    with pm.Model() as weibull_model:\n",
    "        β = pm.Normal(\"β\", 0.0, VAGUE_PRIOR_SD, shape=2)\n",
    "    X_ = shared(X)\n",
    "\n",
    "    with weibull_model:\n",
    "        η = β.dot(X_.T)\n",
    "\n",
    "    with weibull_model:\n",
    "        s = pm.HalfNormal(\"s\", 5.0)\n",
    "\n",
    "    y = np.log(df.time.values)\n",
    "#     y_std = (y - y.mean()) / y.std()\n",
    "\n",
    "#     cens = df.event.values == 0.0\n",
    "\n",
    "    cens_ = shared(cens)\n",
    "\n",
    "    with weibull_model:\n",
    "        y_obs = pm.Gumbel(\"y_obs\", η[~cens_], s, observed=y_std[~cens])\n",
    "\n",
    "    with weibull_model:\n",
    "        y_cens = pm.Potential(\"y_cens\", gumbel_sf(y_std[cens], η[cens_], s))\n",
    "\n",
    "    SEED = 845199  # from random.org, for reproducibility\n",
    "\n",
    "    SAMPLE_KWARGS = {\"chains\": 3, \"tune\": 100, \"random_seed\": [SEED, SEED + 1, SEED + 2]}\n",
    "\n",
    "    with weibull_model:\n",
    "        weibull_trace = pm.sample(**SAMPLE_KWARGS)\n",
    "    return weibull_model, weibull_trace, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(12)\n",
    "def generate():\n",
    "    a = np.random.choice([0, 1], size = 10)\n",
    "    b = np.random.choice([0, 1], size = 10)\n",
    "    return a\n",
    "a = generate()\n",
    "b = generate()\n",
    "comp = a == b\n",
    "print(a)\n",
    "print(b)\n",
    "comp.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trace, dist = tutorial_model(X, y_std, cens)\n",
    "# model_, trace_, dist_ = tutorial_model(X, y_std, cens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = dist == dist_\n",
    "comp.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp = dist == dist_\n",
    "# comp.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = dist == dist1\n",
    "comp.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp = dist == dist2\n",
    "# comp.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist1 = dist\n",
    "# dist2 = dist_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('../../data/brca_metabric_clinical_data.tsv')\n",
    "data_ = data.drop(['Study ID', 'Patient ID', 'Sample ID', 'Type of Breast Surgery', 'Cancer Type Detailed', 'Cohort'\n",
    "                  , 'HER2 status measured by SNP6', 'Hormone Therapy', 'Integrative Cluster', 'Oncotree Code', 'Pam50 + Claudin-low subtype'\n",
    "                  , 'ER status measured by IHC', 'Number of Samples Per Patient', 'Patient\\'s Vital Status', 'Radio Therapy'\n",
    "                   , 'Sex', 'Cancer Type', 'Tumor Stage', 'Sample Type', '3-Gene classifier subtype', 'Tumor Other Histologic Subtype'], axis = 1)\n",
    "\n",
    "leave_columns = ['Cellularity', 'Chemotherapy', 'ER Status', 'HER2 Status', \n",
    "                 'Inferred Menopausal State', 'Primary Tumor Laterality', 'PR Status', 'Neoplasm Histologic Grade']\n",
    "numerical_columns = ['Age at Diagnosis', 'Lymph nodes examined positive', 'Mutation Count',\n",
    "                    'Nottingham prognostic index', 'Relapse Free Status (Months)', 'Tumor Size']\n",
    "labels = ['Overall Survival Status', 'Overall Survival (Months)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data_[data_['Overall Survival Status'].notna()]\n",
    "data_ = data_[data_['Overall Survival (Months)'] > 0]\n",
    "\n",
    "d = {'0:LIVING': False, '1:DECEASED': True}\n",
    "data_['Overall Survival Status'] = data_['Overall Survival Status'].map(d)\n",
    "\n",
    "X_data = data_[numerical_columns+leave_columns]\n",
    "Y_data = data_[labels]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.20, random_state=20)\n",
    "\n",
    "numer_imputer = [([col], [SimpleImputer(missing_values = np.nan, strategy = 'mean')]) for col in numerical_columns]\n",
    "col_imputer = [([col], [SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')]) for col in leave_columns]\n",
    "imputer_mapper = DataFrameMapper(numer_imputer + col_imputer, df_out = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imputer_mapper.fit_transform(X_train)\n",
    "X_test = imputer_mapper.transform(X_test)\n",
    "# x_train_double_temp = inference_mapper.fit_transform(X_train)\n",
    "# categorical_features = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "categorical_names = {}\n",
    "i = 6\n",
    "for feature in leave_columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X_train[feature])\n",
    "    X_train[feature] = le.transform(X_train[feature])\n",
    "    X_test[feature] = le.transform(X_test[feature])\n",
    "    categorical_names[i] = le.classes_\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer_preprocess = [([col], [MinMaxScaler()]) for col in numerical_columns]\n",
    "leave_preprocess = [([col], [OneHotEncoder()]) for col in leave_columns]\n",
    "encoder_mapper = DataFrameMapper(numer_preprocess+leave_preprocess, df_out = False)\n",
    "\n",
    "x_mapper_temp = DataFrameMapper(numer_preprocess+leave_preprocess, df_out = True)\n",
    "x_temp = x_mapper_temp.fit_transform(X_train)\n",
    "\n",
    "x_train = encoder_mapper.fit_transform(X_train)\n",
    "y_train_final = y_train.to_records(index = False, column_dtypes = {'Overall Survival' : 'u1'})\n",
    "\n",
    "y_train_log_t = y_train_final.copy()\n",
    "y_train_log_t['Overall Survival (Months)'] = np.log1p(y_train_final['Overall Survival (Months)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915\n",
      "0.896\n"
     ]
    }
   ],
   "source": [
    "ref_estimator = FastSurvivalSVM(rank_ratio=0.0, max_iter=1000, tol=1e-5, random_state=0)\n",
    "ref_estimator.fit(x_train, y_train_log_t)\n",
    "\n",
    "cindex = concordance_index_censored(\n",
    "    y_train_final['Overall Survival Status'],\n",
    "    y_train_final['Overall Survival (Months)'],\n",
    "    -ref_estimator.predict(x_train),  # flip sign to obtain risk scores\n",
    ")\n",
    "print(round(cindex[0], 3))\n",
    "\n",
    "y_test_final = y_test.to_records(index = False, column_dtypes = {'Overall Survival' : 'u1'})\n",
    "y_test_final\n",
    "x_test = encoder_mapper.transform(X_test)\n",
    "\n",
    "cindex = concordance_index_censored(\n",
    "    y_test_final['Overall Survival Status'],\n",
    "    y_test_final['Overall Survival (Months)'],\n",
    "    -ref_estimator.predict(x_test),  # flip sign to obtain risk scores\n",
    ")\n",
    "print(round(cindex[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "def predict_fn(x):\n",
    "    df = pd.DataFrame(x, columns = numerical_columns+leave_columns)\n",
    "    return ref_estimator.predict(encoder_mapper.transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy() ,feature_names = numerical_columns+leave_columns,\n",
    "                                                   categorical_features=categorical_features, \n",
    "                                                   categorical_names=categorical_names, kernel_width=3, mode='regression', feature_selection = 'none', random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    y = np.exp(x)\n",
    "    f_x = y / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "def censored_distances(survival_status, event, distances):\n",
    "    cens_dist = np.abs(survival_status - event)\n",
    "    return np.sqrt(np.square(distances)+cens_dist)\n",
    "\n",
    "def gumbel_sf(y, μ, σ):\n",
    "    return 1.0 - tt.exp(-tt.exp(-(y - μ) / σ))\n",
    "\n",
    "def train_model(sample_X, y_std, cens, distances):\n",
    "    cens_ = shared(cens)\n",
    "    with pm.Model() as model:\n",
    "        distances_ = pm.Data(\"distance\", distances)\n",
    "        sample_X_ = pm.Data(\"data\", sample_X)\n",
    "        sigma_squared = pm.HalfNormal(\"sigma_squared\", 5)\n",
    "        beta = pm.Normal(\"beta\", 0.0, sigma_squared, shape = sample_X.shape[1])\n",
    "        eta = beta.dot(sample_X_.T)\n",
    "        y_obs = pm.Gumbel(\"y_obs\", eta[~cens_], sigma_squared/distances_[~cens_], observed=y_std[~cens])\n",
    "        y_cens = pm.Potential(\"y_cens\", gumbel_sf(y_std[cens], eta[cens_], sigma_squared/distances_[cens_]))\n",
    "    SEED = 845199  # from random.org, for reproducibility\n",
    "    SAMPLE_KWARGS = {\"chains\": 3, \"tune\": 100, \"random_seed\": [SEED, SEED + 1, SEED + 2], \"target_accept\" : 0.9}\n",
    "    with model:\n",
    "        weibull_trace = pm.sample(**SAMPLE_KWARGS)\n",
    "    return model, weibull_trace, cens_\n",
    "\n",
    "def generate_samples(explainer, point, i, y_train, y_test_final, S, N, A, batch_size, predict_fn):\n",
    "#     x_test = X_test.to_numpy()\n",
    "    samples, y_std, distances = explainer.generate_samples(point, predict_fn, S)\n",
    "    unique, counts = np.unique(y_train['Overall Survival Status'], return_counts=True)\n",
    "    p1 = counts[0]/sum(counts)\n",
    "    p2 = counts[1]/sum(counts)\n",
    "    rng = default_rng(random_state)\n",
    "    event = rng.choice([0, 1], size = S-1, p = [p1, p2])\n",
    "    X_sample = np.empty((samples.shape[0], samples.shape[1]+1))\n",
    "    X_sample[:, 0] = 1\n",
    "    for i in range(samples.shape[1]):\n",
    "        X_sample[:, i+1] = samples[:, i]\n",
    "    X_sample = X_sample[1:, :]\n",
    "    y_std = y_std[1:]\n",
    "    distances = distances[1:]\n",
    "    distances = censored_distances(y_test_final['Overall Survival Status'][i], event, distances)\n",
    "#     return samples, X_sample, y_std, distances\n",
    "    model, weibull_trace, cens_ = train_model(X_sample, y_std, event==0, distances)\n",
    "    return samples, X_sample, y_std, event==0, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pymc3/sampling.py:468: FutureWarning: In an upcoming release, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  FutureWarning,\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 4 jobs)\n",
      "NUTS: [beta, sigma_squared]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3300' class='' max='3300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3300/3300 00:14<00:00 Sampling 3 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 100 tune and 1_000 draw iterations (300 + 3_000 draws total) took 27 seconds.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "S = 50\n",
    "A = 100\n",
    "N = 50\n",
    "index = 5\n",
    "point = X_test.to_numpy()[index]\n",
    "samples, X_sample, y_std, c, distances = generate_samples(explainer, point, index, y_train, y_test_final, S, N, A, batch_size, predict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = samples == samples_\n",
    "print(comp.all())\n",
    "\n",
    "comp = distances == distances_\n",
    "print(comp.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_ = samples\n",
    "distances_ = distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison = X_sample == X_sample_\n",
    "# print(comparison.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison = first_iteration == X_sample\n",
    "# print(comparison.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison = first_iteration_ == X_sample_\n",
    "# print(comparison.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_iteration = X_sample\n",
    "# first_iteration_ = X_sample_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_sample_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, trace, _ = train_model(X_sample, y_std, c, distances)\n",
    "# model_, trace_, _ = train_model(X_sample_, y_std_, c_, distances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.summary(trace_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # distances = np.random.choice([2, 1], size = X.shape[0], p = [0.5, 0.5])\n",
    "# distances = np.array([1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1,\n",
    "#        1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2])\n",
    "# model, trace, _ = wrapper(X, y_std, cens, distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['metastized'] = df['metastized'].apply(lambda x : x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_patient, _ = df.shape\n",
    "\n",
    "# X = np.empty((n_patient, 2))\n",
    "# X[:, 0] = 1.0\n",
    "# X[:, 1] = df.metastized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_, trace_, _ = train_model(X, y_std, cens, distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.summary(trace_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 2\n",
    "\n",
    "# def func(x):\n",
    "#     x += 1\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = func(3)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
