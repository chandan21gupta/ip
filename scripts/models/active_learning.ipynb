{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.svm import FastSurvivalSVM\n",
    "import lifelines\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "# from sklearn_pandas import CategoricalImputer\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import kendall_w as kw\n",
    "\n",
    "import warnings\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from pymc3.distributions import Interpolated\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from statsmodels import datasets\n",
    "from theano import shared\n",
    "from theano import tensor as tt\n",
    "\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('../../data/brca_metabric_clinical_data.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data.drop(['Study ID', 'Patient ID', 'Sample ID', 'Type of Breast Surgery', 'Cancer Type Detailed', 'Cohort'\n",
    "                  , 'HER2 status measured by SNP6', 'Hormone Therapy', 'Integrative Cluster', 'Oncotree Code', 'Pam50 + Claudin-low subtype'\n",
    "                  , 'ER status measured by IHC', 'Number of Samples Per Patient', 'Patient\\'s Vital Status', 'Radio Therapy'\n",
    "                   , 'Sex', 'Cancer Type', 'Tumor Stage', 'Sample Type', '3-Gene classifier subtype', 'Tumor Other Histologic Subtype'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_columns = ['Cellularity', 'Chemotherapy', 'ER Status', 'HER2 Status', \n",
    "                 'Inferred Menopausal State', 'Primary Tumor Laterality', 'PR Status', 'Neoplasm Histologic Grade']\n",
    "numerical_columns = ['Age at Diagnosis', 'Lymph nodes examined positive', 'Mutation Count',\n",
    "                    'Nottingham prognostic index', 'Relapse Free Status (Months)', 'Tumor Size']\n",
    "labels = ['Overall Survival Status', 'Overall Survival (Months)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data_[data_['Overall Survival Status'].notna()]\n",
    "data_ = data_[data_['Overall Survival (Months)'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'0:LIVING': False, '1:DECEASED': True}\n",
    "data_['Overall Survival Status'] = data_['Overall Survival Status'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data_[numerical_columns+leave_columns]\n",
    "Y_data = data_[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.20, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer_imputer = [([col], [SimpleImputer(missing_values = np.nan, strategy = 'mean')]) for col in numerical_columns]\n",
    "col_imputer = [([col], [SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')]) for col in leave_columns]\n",
    "imputer_mapper = DataFrameMapper(numer_imputer + col_imputer, df_out = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imputer_mapper.fit_transform(X_train)\n",
    "X_test = imputer_mapper.transform(X_test)\n",
    "# x_train_double_temp = inference_mapper.fit_transform(X_train)\n",
    "# categorical_features = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "categorical_names = {}\n",
    "i = 6\n",
    "for feature in leave_columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X_train[feature])\n",
    "    X_train[feature] = le.transform(X_train[feature])\n",
    "    X_test[feature] = le.transform(X_test[feature])\n",
    "    categorical_names[i] = le.classes_\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer_preprocess = [([col], [MinMaxScaler()]) for col in numerical_columns]\n",
    "leave_preprocess = [([col], [OneHotEncoder()]) for col in leave_columns]\n",
    "encoder_mapper = DataFrameMapper(numer_preprocess+leave_preprocess, df_out = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mapper_temp = DataFrameMapper(numer_preprocess+leave_preprocess, df_out = True)\n",
    "x_temp = x_mapper_temp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = encoder_mapper.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_final = y_train.to_records(index = False, column_dtypes = {'Overall Survival' : 'u1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log_t = y_train_final.copy()\n",
    "y_train_log_t['Overall Survival (Months)'] = np.log1p(y_train_final['Overall Survival (Months)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915\n"
     ]
    }
   ],
   "source": [
    "ref_estimator = FastSurvivalSVM(rank_ratio=0.0, max_iter=1000, tol=1e-5, random_state=0)\n",
    "ref_estimator.fit(x_train, y_train_log_t)\n",
    "\n",
    "cindex = concordance_index_censored(\n",
    "    y_train_final['Overall Survival Status'],\n",
    "    y_train_final['Overall Survival (Months)'],\n",
    "    -ref_estimator.predict(x_train),  # flip sign to obtain risk scores\n",
    ")\n",
    "print(round(cindex[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_final = y_test.to_records(index = False, column_dtypes = {'Overall Survival' : 'u1'})\n",
    "y_test_final\n",
    "x_test = encoder_mapper.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896\n"
     ]
    }
   ],
   "source": [
    "# pred_y = np.expm1(ref_estimator.predict(x_test))\n",
    "cindex = concordance_index_censored(\n",
    "    y_test_final['Overall Survival Status'],\n",
    "    y_test_final['Overall Survival (Months)'],\n",
    "    -ref_estimator.predict(x_test),  # flip sign to obtain risk scores\n",
    ")\n",
    "print(round(cindex[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "def predict_fn(x):\n",
    "    df = pd.DataFrame(x, columns = numerical_columns+leave_columns)\n",
    "    return ref_estimator.predict(encoder_mapper.transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy() ,feature_names = numerical_columns+leave_columns,\n",
    "                                                   categorical_features=categorical_features, \n",
    "                                                   categorical_names=categorical_names, kernel_width=3, mode='regression', feature_selection = 'none', random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    y = np.exp(x)\n",
    "    f_x = y / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "def censored_distances(survival_status, event, distances):\n",
    "    cens_dist = np.abs(survival_status - event)\n",
    "    return np.sqrt(np.square(distances)+cens_dist)\n",
    "\n",
    "def gumbel_sf(y, μ, σ):\n",
    "    return 1.0 - tt.exp(-tt.exp(-(y - μ) / σ))\n",
    "\n",
    "def train_model(sample_X, y_std, cens, distances):\n",
    "    cens_ = shared(cens)\n",
    "    with pm.Model() as model:\n",
    "        distances_ = pm.Data(\"distance\", distances)\n",
    "        sample_X_ = pm.Data(\"data\", sample_X)\n",
    "        sigma_squared = pm.HalfNormal(\"sigma_squared\", 5)\n",
    "        beta = pm.Normal(\"beta\", 0.0, sigma_squared, shape = sample_X.shape[1])\n",
    "        eta = beta.dot(sample_X_.T)\n",
    "        y_obs = pm.Gumbel(\"y_obs\", eta[~cens_], sigma_squared/distances_[~cens_], observed=y_std[~cens])\n",
    "        y_cens = pm.Potential(\"y_cens\", gumbel_sf(y_std[cens], eta[cens_], sigma_squared/distances_[cens_]))\n",
    "    SEED = 845199  # from random.org, for reproducibility\n",
    "    SAMPLE_KWARGS = {\"chains\": 3, \"tune\": 100, \"random_seed\": [SEED, SEED + 1, SEED + 2], \"target_accept\" : 0.9}\n",
    "    with model:\n",
    "        weibull_trace = pm.sample(**SAMPLE_KWARGS)\n",
    "    return model, weibull_trace, cens_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def censored_focussed_sampling(explainer, point, i, y_train, y_test_final, S, N, A, batch_size, predict_fn):\n",
    "#     x_test = X_test.to_numpy()\n",
    "    samples, y_std, distances = explainer.generate_samples(point, predict_fn, S)\n",
    "    unique, counts = np.unique(y_train['Overall Survival Status'], return_counts=True)\n",
    "    p1 = counts[0]/sum(counts)\n",
    "    p2 = counts[1]/sum(counts)\n",
    "    rng = default_rng(random_state)\n",
    "    event = rng.choice([0, 1], size = S-1, p = [p1, p2])\n",
    "    X_sample = np.empty((samples.shape[0], samples.shape[1]+1))\n",
    "    X_sample[:, 0] = 1\n",
    "    for i in range(samples.shape[1]):\n",
    "        X_sample[:, i+1] = samples[:, i]\n",
    "    X_sample = X_sample[1:, :]\n",
    "    y_std = y_std[1:]\n",
    "    distances = distances[1:]\n",
    "    distances = censored_distances(y_test_final['Overall Survival Status'][i], event, distances)\n",
    "    model, weibull_trace, cens_ = train_model(X_sample, y_std, event==0, distances)\n",
    "#     return model, weibull_trace, cens_\n",
    "    for _ in range(0, N-S, batch_size):\n",
    "        samples, y_std_sampled, distances_sampled = explainer.generate_samples(x_test[i], predict_fn, A)\n",
    "        X_sampled = np.empty((samples.shape[0], samples.shape[1]+1))\n",
    "        X_sampled[:, 0] = 1\n",
    "        for i in range(samples.shape[1]):\n",
    "            X_sampled[:, i+1] = samples[:, i]\n",
    "        X_sampled = X_sampled[1:, :]\n",
    "        y_std_sampled = y_std_sampled[1:]\n",
    "        rng_ = default_rng(random_state)\n",
    "        event_sampled = rng_.choice([0, 1], size = A-1, p = [p1, p2])\n",
    "        distances_sampled = censored_distances(y_test_final['Overall Survival Status'][i], event_sampled, distances_sampled[1:])\n",
    "        rng__ = default_rng(random_state)\n",
    "        cens_pp = rng__.choice([False, True], size = A-1, p = [1, 0])\n",
    "        cens_.set(cens_pp)\n",
    "        with model:\n",
    "            pm.set_data({\"data\" : X_sampled, \"distances\" : distances_sampled})\n",
    "            pp_weibull_trace = pm.sample_posterior_predictive(weibull_trace, samples=1500)\n",
    "        p_test_pred = np.square(pp_weibull_trace[\"y_obs\"].std(axis=0))\n",
    "        normalized_sd = softmax(p_test_pred)\n",
    "        rng___ = default_rng(random_state)\n",
    "        top_k = rng___.choice([i for i in range(p_test_pred.shape[0])], size = batch_size, p = normalized_sd, replace = False)\n",
    "        selected_X = X_sampled[top_k]\n",
    "        selected_dist = distances_sampled[top_k]\n",
    "        selected_event = event_sampled[top_k]\n",
    "#         cens_.set_value(selected_event == 0)\n",
    "        selected_y_std = y_std_sampled[top_k]\n",
    "        X = np.vstack([X, selected_X])\n",
    "        y_std = np.hstack([y_std, selected_y_std])\n",
    "        distances = np.hstack([distances, selected_dist])\n",
    "        event = np.hstack([event, selected_event])\n",
    "        model, weibull_trace = train_model(X, y_std, event==0, distances)\n",
    "    df = az.summary(weibull_trace)\n",
    "    return df['mean'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pymc3/sampling.py:468: FutureWarning: In an upcoming release, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  FutureWarning,\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 4 jobs)\n",
      "NUTS: [beta, sigma_squared]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3300' class='' max='3300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3300/3300 00:12<00:00 Sampling 3 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 100 tune and 1_000 draw iterations (300 + 3_000 draws total) took 23 seconds.\n",
      "The acceptance probability does not match the target. It is 0.9621464759480016, but should be close to 0.9. Try to increase the number of tuning steps.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/arviz/data/io_pymc3.py:91: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-53c5246741be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcensored_focussed_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "S = 50\n",
    "A = 100\n",
    "N = 50\n",
    "index = 5\n",
    "point = X_test.to_numpy()[index]\n",
    "model, trace, _  = censored_focussed_sampling(explainer, point, index, y_train, y_test_final, S, N, A, batch_size, predict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = model['data'].get_value() == model_['data'].get_value()\n",
    "print(comparison.all())\n",
    "# az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "S = 50\n",
    "A = 100\n",
    "N = 50\n",
    "index = 5\n",
    "point = X_test.to_numpy()[index]\n",
    "model_, trace_, _  = censored_focussed_sampling(explainer, point, index, y_train, y_test_final, S, N, A, batch_size, predict_fn)\n",
    "model__, trace__, _ = censored_focussed_sampling(explainer, point, index, y_train, y_test_final, S, N, A, batch_size, predict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = model_[\"data\"].get_value()\n",
    "values_ = model__[\"data\"].get_value()\n",
    "comparison = values == values_\n",
    "print(comparison.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = model[\"distance\"].get_value()\n",
    "values_ = model_[\"distance\"].get_value()\n",
    "comparison = values == values_\n",
    "print(comparison.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = c.get_value(borrow = True)\n",
    "values_ = c.get_value(borrow = True)\n",
    "comparison = values == values_\n",
    "print(comparison.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
